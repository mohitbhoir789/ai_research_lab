

# ğŸ§  AI Research Assistant

An intelligent research assistant powered by LLMs and LangGraph that helps you generate research proposals, explore topics, summarize papers, and more. Inspired by ChatGPT â€” with chat history, multi-agent reasoning, and integrated document support.

---

## ğŸš€ Features

- âœ… **Chat Interface** with research-focused LLM workflows
- âœ… **Multi-agent reasoning**: Planner, Researcher, Critic, Verifier, Summarizer
- âœ… **Smart Mode Switching**: Summary or Research based on query
- âœ… **LLM Integration**: Groq, HuggingFace, Gemini (extensible)
- âœ… **LangGraph**-style workflows with traceable steps
- âœ… **Chat History**: Rename, delete, and switch between sessions
- âœ… **Streamlit UI**: WhatsApp-style bubbles, avatars, PDF upload support

---

## ğŸ“ Project Structure

```
ai_research_lab/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py             # FastAPI entrypoint
â”‚   â”‚   â”œâ”€â”€ agents/             # All agent logic (planner, critic, etc.)
â”‚   â”‚   â”œâ”€â”€ mcp/                # MCPServer (LangGraph-style orchestrator)
â”‚   â”‚   â”œâ”€â”€ utils/              # Embedding, LLM handler, etc.
â”‚   â”‚   â””â”€â”€ schemas/            # Pydantic types
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py                  # Streamlit app interface
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Installation

### 1. Clone the repo

```bash
git clone https://github.com/your-username/ai_research_lab.git
cd ai_research_lab
```

### 2. Create virtual environment

```bash
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

---

## âš™ï¸ Configuration

Create a `.env` file in the backend folder:

```env
GROQ_API_KEY=your-groq-key
PINECONE_API_KEY=your-pinecone-key
PINECONE_INDEX_NAME=your-index-name
```

---

## â–¶ï¸ Run the App

```bash
cd frontend
streamlit run gui.py
```

âœ… This will **automatically launch the FastAPI backend** if it's not already running.

---

## ğŸ“š Example Prompts

- `deep learning` â†’ Gets a one-paragraph summary.
- `explain deep learning` â†’ Detailed educational explanation.
- `deep learning advancements` â†’ Retrieves and summarizes latest research.
- `new research on deep learning` â†’ Proposes new research, generates plan, critique, and summary.

---

## ğŸ§© Tech Stack

- **LangChain + LangGraph** for reasoning flow
- **Groq LLMs** (LLaMA-3), with extensible model support
- **Pinecone** for RAG + vector search
- **FastAPI** for backend
- **Streamlit** for frontend
- **Wikipedia & arXiv APIs** for context

---

## ğŸ§ª Future Enhancements

- ğŸ“„ PDF parsing and in-chat citations
- ğŸ§  Agent memory / scratchpad
- ğŸ“Š Admin dashboard for usage analytics
- ğŸŒ Multi-model routing (Groq vs Gemini vs HuggingFace)

---
